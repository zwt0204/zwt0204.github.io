---
layout:     post
title:      "token"
subtitle:   " \"token\""
date:       2024-03-13 18:00:00
mathjax: true
author:     "zwt"
header-img: "img/post-bg-2015.jpg"
catalog: false
tags:
    - llms
---
* TOC
{:toc}

# 大词表优劣

## 优势
LLM通常是自回归，解码的token越多，速度越慢。通过增大词表就可以缩短序列的长度，提高压缩比率。也就是说模型处理相同的序列所对应的token会变少（极端情况下每句话都对应一个token，则一个序列就是一个token对应，当然不可能这么做）相应的解码步数也会变少，从而提升了解码速度。与此同时语言模型训练的时候采取的都是teacher forcing，缩短序列长度也可以缓解其所带来的exposure bias问题，提升模型效果。

## 劣势
割裂token之间字符级别的联系，影响泛化性，有时会损失在某些任务上的能力。
比如：
```
如“import numpy as np”都变成了一个token，然后发现当用户输入“import numpy”时，模型无法续写出“ as np”。原因很简单，“import numpy as np”被当作了一个token，于是当“import numpy”单独出现时，模型会发现它后面永远不会接“ as np”（接“ as np”的都被合并成单独的“import numpy as np”了），自然也无法完成续写。
```


# 参考
1[科学空间](https://spaces.ac.cn/archives/9762)














