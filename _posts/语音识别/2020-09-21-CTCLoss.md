---
layout:     post
title:      "CTCloss"
subtitle:   " \"损失函数\""
date:       2020-09-21 18:00:00
mathjax: true
author:     "zwt"
header-img: "img/post-bg-2015.jpg"
catalog: false
tags:
    - 语音识别
---
* TOC
{:toc}
# 目的

针对语音识别中字符与因素的对应，手写识别中字符与图片的对应、视频标记中动作的标记等诸如输入与输出对应的问题。
![](https://zwt0204.github.io//img/ctcloss.png)
上述场景下（各个输入之间没有明确的界限），正是CTC（Connectionist Temporal Classiﬁcation）用武之地。CTC是一种让网络自动学会对齐的好方法，十分适合语音识别和书写识别。

# 基本原理

![](https://zwt0204.github.io//img/ctcloss1.png)
如上图所示：ctcloss在字符与字符之间加入特殊的字符$\epsilon$,如果是连续相同的字符之间也要加入特殊符号来做区分。

# 主要解决的问题

例如对于一个输入序列：$X = [x_1, x_2, x_3,....x_T]$在语音识别中其表示的就是T个帧，每一个帧$x_t$是一个MFCC提取的n维特征，输出序列为：$Y = [y_1, y_2, y_3,....y_U]$
对于上述的任务来说，很难说将其转化为一般的分类任务，因为：
```
X和Y都是变长的
X和Y的长度也是变化的，也就是说X和Y的长度之间不存在简单的比例对应关系
训练数据中X和Y很难有对齐的情况
```
也许有人说可以将其认为是序列标注问题，但是注意，一般的序列标注问题是存在清晰的边界的，输入输出都是逻辑符号，符号之间边界明显，可以很好的建模，同时在前期也被当作分类任务来处理。但是对于语音识别问题，输入的是 语音信号，输入之间没有明显的界限，输入和输出没有办法进行对齐。

CTC的提出就是为了解决这一类问题，对于一个给定的X，CTC可以对所有可能的Y计算P(Y given X)。炸这样就可以计算出相应的某个Y的概率。

CTC给出的是一个较优的路径，是在合理的时间内选择一个可以接受的解。

与softmax不同，softmax需要严格的对齐来计算，ctcloss不需要严格的对齐，通过前向算法对求解的速度进行优化。

# 详解

对于给定的X，CTC可以计算出所有输出Y的概率，这个计算的关键在于CTC对于输入输出的对齐处理。

## 对齐

![](https://zwt0204.github.io//img/ctcloss2.png)
主要解决了两个问题，比如语音识别中的静音，不应该有输出，第二个问题，输出有相同的字符。
![](https://zwt0204.github.io//img/ctcloss3.png)

## 损失函数

有了ctc对齐之后，就可以很自然的计算概率P(Y|X)了，计算过程如下：
![](https://zwt0204.github.io//img/ctcloss4.png)
如上图所示RNN会计算每一个时刻的输出概率分布$p_t(a given X)$，表示t时刻输出字符a的概率。这些概率中有些很小可以忽略，有些对应的输出一样，就加起来。形式化的表示为
$P(Y \mid X)=\sum_{A \in \mathcal{A}_{X, Y}} \prod_{t=1}^{T} p_{t}\left(a_{t} \mid X\right)$

因为在输出y的任意两个字符之间都可以对应空字符，所以我们在y的每一个字符之间都插入空字符得到$Z=[\epsilon , y_1, \epsilon , y_U, \epsilon]$。假设$\alpha_{s,t}$表示输入序列的前s个字符$X_{1:s}$和输出的前t个字符$Z_{1:t}$对齐时所有合法路径的概率和。有了t时刻之前的$\alpha$，我们就可以计算t时刻的$\alpha$，这样我们就可以使用动态规划算法，最后得到T时刻的$\alpha$之后我们就可以得到P(Y|X)。
![](https://zwt0204.github.io//img/ctcloss5.png)
![](https://zwt0204.github.io//img/ctcloss6.png)
![](https://zwt0204.github.io//img/ctcloss7.png)
![](https://zwt0204.github.io//img/ctcloss8.png)
![](https://zwt0204.github.io//img/ctcloss9.png)
![](https://zwt0204.github.io//img/ctcloss10.png)

# 预测

一种最简单直接的方法：对每一个时刻的输出都选取概率最大的输出，这样就可以得到概率最大的一条路径。$A^{*}=\underset{A}{\operatorname{argmax}} \prod_{t=1}^{T} p_{t}\left(a_{t} \mid X\right)$

可以通过对beam search的改进来完成预测解码：
一般的beam search：
![](https://zwt0204.github.io//img/ctcloss11.png)

对上述基础的beam search进行改进：如下图所示将输出相同的路径合并，同时去掉空字符，然后所有相同输出的概率累加起来。例如再t为3的时候，下方的$b,a, \epsilon$和$b,a,a$被合并为相同的$b,a$。但是为了防止中间有空字符的情况，需要记录那些最后一个字符为空。
![](https://zwt0204.github.io//img/ctcloss12.png)
![](https://zwt0204.github.io//img/ctcloss13.png)



# 特点

ctc假设输出是相互独立的，所以没有办法学习到输出的上下文关系，也就是缺失了语言模型
ctc的对齐方式是单调的，适用于语音识别但是对于其他诸如翻译等场景是不适合的
ctc的输入与输出是多对一的关系.输入序列的长度一定大于等于输出长度。

# 参考
1. [李理的博客ctc](http://fancyerii.github.io/books/ctc/)
2. [ctcloss](https://blog.csdn.net/weixin_37721058/article/details/99702801)
3. [ctcloss解释](https://xiaodu.io/ctc-explained/)














