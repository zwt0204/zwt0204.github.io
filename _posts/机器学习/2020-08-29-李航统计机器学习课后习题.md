---
layout:     post
title:      "统计机器学习"
subtitle:   " \"统计机器学习\""
date:       2020-08-29 15:30:00 
mathjax: true
author:     "zwt"
header-img: "img/post-bg-2015.jpg"
catalog: false
tags:
    - 机器学习
---
* TOC
{:toc}
# 第一章

1. 说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习三要素。伯努利模型是定义在取之为0和1的随机变量上的概率分布。假设观测到伯努利模型n次独立的数据生成结果为，k次为1，这时可以用极大似然估计或者贝叶斯估计来估计结果为1的概率。

   答：
   $$
   \begin{array}{|l|l|l|l|}\hline & \text { 模型 } & \text { 策略 } & \text { 算法 } \\ \hline \text { 极大似然估计 } & \text { 条件概案 } & \text { 经验风险最小化 } & \text { 求解析解 } \\ \hline \text { 贝早斯估计 } & \text { 条件概案 } & \text { 结构风险最小化 } & \text { 求数值解 } \\ \hline\end{array}
   $$
   
   $$
   设P(Y=1) = \theta \\
   P(Y=0) = 1 - \theta \\
   极大似然估计为：\\
   L(\theta) = \prod_{i=1}^n P(A_i) = \theta ^k (1 - \theta)^{n-k} \\
   似然函数的对数为：\\
   log(L(\theta)) = log(\theta ^k (1 - \theta)^{n-k})= k log(\theta) + (n-k)log(1-\theta)\\
   求导并另导数为0:\partial(\log (L(\theta)) / \partial(\theta)=k /(\theta)-(n-k) /(1-\theta)=0得到\theta=k/n \\
   贝叶斯估计：\\
   P\left(\theta \mid A_{1}, A_{2} \ldots A_{n}\right)=\frac{P\left(A_{1}, A_{2}, \ldots A_{n} \mid \theta\right) \times \pi(\theta)}{P\left(A_{1}, A_{2}, \ldots A_{n}\right)}\\
   求解:\theta=\operatorname{argmax}_{\theta} P\left(A_{1}, A_{2}, \ldots A_{n} \mid \theta\right) * P(\theta)=\operatorname{argmax}_{\theta} P\left(A_{i} \mid \theta\right) * P(\theta)=\operatorname{argmax}_{\theta}\left(\theta^{k} *(1-\theta)^{n-k} * \theta^{a-1} *\left(1-\theta^{b-1}\right)\right.\\
   \theta=\frac{k+(a-1)}{n+(a-1)+(b-1)},其中a和b满足beta分布
   $$
   

2. 通过经验风险最小化推导极大似然估计，证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。
   $$
   粗糙的解释：最大似然估计：max \frac{1}{n} \sum_{i=1}^n log(f(x_i)|\theta)也就是经验风险最小化：min-\frac{1}{n} \sum_{i=1}^n log(f(x_i)|\theta)\\
   所以模型时伯努利模型，损失函数为对数损失函数，会求解经验风险最小化等价于最大似然估计
   $$

   $$
   精细的解释：模型时条件概率：f(x) = P(Y|X) = \frac{P(X,Y)}{P(X)}\\
   对数损失的定义为：L(Y, P(Y|X)) = -logP(Y|X)\\
   此时经验损失为：R = \frac{1}{N} \sum_{i=1}^N L(Y_i, f(X_i)) = \frac{1}{N} \sum_{i=1}^N L(Y_i, P(Y_i | X_i))=\frac{1}{N} \sum_{i=1}^N -logP(Y_i|X_i) = -\frac{1}{N} log (\prod_{i=1}^N \frac{P(X_i, Y_i)}{P(X_i)})
   $$

   

# 第二章

