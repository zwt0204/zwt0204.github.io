---
layout:     post
title:      "微调"
subtitle:   " \"微调\""
date:       2024-03-18 18:00:00
mathjax: true
author:     "zwt"
header-img: "img/post-bg-2015.jpg"
catalog: false
tags:
    - llms
---
* TOC
{:toc}
# 为什么需要高效微调
自然语言处理的任务中，从bert出现之后，基本的流程就是预训练+微调。微调需要针对每个下游任务来进行，同时微调后的模型和原始模型是一样大的。这种形式对于bert、gpt来说还勉强可以接受，但是对于再大的模型如gpt3(175B)等就是一个很大的挑战了。
所以我们需要一些可以快速的微调类似gpt3类的大模型，同时也不需要太多的存储。
# prompt tuning

# p-tuning

# p-tuningv2

# adapt tuning

# lora


# qlora
